{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x7BabUMZtAJT"
   },
   "source": [
    "## 4.4 VGG16\n",
    "\n",
    "Data Preprocess of VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16yFDDjKwvCL"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from imageio import imread\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.image_utils import img_to_array\n",
    "import keras\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Nd6aVBgw01g"
   },
   "outputs": [],
   "source": [
    "# Settings \n",
    "num_classes = 10\n",
    "test_size = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHju8_99tEW9"
   },
   "source": [
    "Read Image and Convert to 3D Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x0DSTAtTuoZs"
   },
   "outputs": [],
   "source": [
    "def get_img(data_path): \n",
    "  ## Getting image array from path: \n",
    "  img = PIL.Image.open(data_path)\n",
    "  img = img.convert(\"L\")\n",
    "  img = img_to_array(img)\n",
    "  img = np.resize(img, (100, 100, 3))\n",
    "  return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p1eDElM6i80O"
   },
   "source": [
    "Get dataset from picture and then split to train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51GeBQZ28elF",
    "outputId": "1cd5fa75-86a2-4f43-d5bc-aa18d08b555f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "(1649, 100, 100, 3)\n",
      "(413, 100, 100, 3)\n",
      "(1649, 10)\n",
      "(413, 10)\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "dataset_path = \"/content/drive/MyDrive/Dataset\"\n",
    "\n",
    "## Getting all data from data path\n",
    "labels = sorted(listdir(dataset_path))\n",
    "X = []\n",
    "Y = []\n",
    "for i, label in enumerate(labels): \n",
    "  data_path = dataset_path + \"/\" + label\n",
    "  \n",
    "  for data in listdir(data_path): \n",
    "    img = get_img(data_path + \"/\" + data)\n",
    "    X.append(img)\n",
    "    Y.append(i)\n",
    "## create dataset \n",
    "X = 1 - np.array(X).astype(\"float32\") /255\n",
    "Y = np.array(Y).astype(\"float32\")\n",
    "Y = to_categorical(Y, num_classes)\n",
    "\n",
    "X, X_test, Y, Y_test = train_test_split(X, Y, test_size=test_size, random_state = 42)\n",
    "print(X.shape)\n",
    "print(X_test.shape)\n",
    "print(Y.shape)\n",
    "print(Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7bcUyDrA_bb-"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tf.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9HBS8wnVPPai"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import time\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras import initializers\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "import math \n",
    "from keras import applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4CKh1K-AebKb"
   },
   "outputs": [],
   "source": [
    "img_height = 100\n",
    "img_width = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59QCRaTqs3x7"
   },
   "source": [
    "# VGG16\n",
    "\n",
    "Learning rate has been adjusted between le-3, le-4, le-5, le-6, the result is le-5 can provide the best performance. Drop out rate of 0.3, 0.4, 0.5 has been tried and ultimately 0.4 has a relativley good performance. Initially epoch has been set to 10 but the performance was not pretty well. By increasing to 50, the model has been trained into the accuracy of 98%\n",
    "GlobalAveragePooling2D()for creating feature map for each category of the model and unfreezing the base model and retrain the whole model for fine-tuning has been applied in all transfer learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QHp7OmgMx5UV"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "#base_model = VGG16(include_top = False, weights = 'imagenet',input_shape=(100,100,3))\n",
    "base_model = keras.applications.VGG16(\n",
    "    weights='imagenet', \n",
    "    input_shape=(img_height, img_width, 3),\n",
    "    include_top=False)\n",
    "#base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FJrgYK-74q8W"
   },
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hHLu9-bS2BOS"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(img_height, img_width, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SM4FZ_vA2BuC"
   },
   "outputs": [],
   "source": [
    "x=tf.keras.applications.vgg16.preprocess_input(\n",
    "    inputs, data_format=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ADo_0LXY3ls2"
   },
   "outputs": [],
   "source": [
    "x = base_model(x, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dropout(0.4)(x)\n",
    "outputs = keras.layers.Dense(10)(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7a8hWH9_9td2",
    "outputId": "be76503d-15f4-4218-bbad-f6d89c252b2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem_4   (None, 100, 100, 3)      0         \n",
      " (SlicingOpLambda)                                               \n",
      "                                                                 \n",
      " tf.nn.bias_add_4 (TFOpLambd  (None, 100, 100, 3)      0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, 3, 3, 512)         14714688  \n",
      "                                                                 \n",
      " global_average_pooling2d_4   (None, 512)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,719,818\n",
      "Trainable params: 5,130\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5P7XJT_lR9fp",
    "outputId": "7970c574-40c0-43e3-9233-e338eb4d43f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "52/52 [==============================] - 4s 58ms/step - loss: 4.3663 - accuracy: 0.1049 - val_loss: 2.3922 - val_accuracy: 0.0969\n",
      "Epoch 2/3\n",
      "52/52 [==============================] - 2s 48ms/step - loss: 2.8542 - accuracy: 0.1104 - val_loss: 2.3356 - val_accuracy: 0.0847\n",
      "Epoch 3/3\n",
      "52/52 [==============================] - 3s 48ms/step - loss: 2.5525 - accuracy: 0.1013 - val_loss: 2.3267 - val_accuracy: 0.0847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbe0732ae20>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X, Y, epochs=3, validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ESYLlsRq7PWM",
    "outputId": "0f93408e-5c6e-4923-fa11-85b03d736eb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem_4   (None, 100, 100, 3)      0         \n",
      " (SlicingOpLambda)                                               \n",
      "                                                                 \n",
      " tf.nn.bias_add_4 (TFOpLambd  (None, 100, 100, 3)      0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, 3, 3, 512)         14714688  \n",
      "                                                                 \n",
      " global_average_pooling2d_4   (None, 512)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,719,818\n",
      "Trainable params: 14,719,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "52/52 [==============================] - 7s 121ms/step - loss: 2.3724 - accuracy: 0.0958 - val_loss: 2.3056 - val_accuracy: 0.1211\n",
      "Epoch 2/50\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 2.3099 - accuracy: 0.1079 - val_loss: 2.2978 - val_accuracy: 0.1162\n",
      "Epoch 3/50\n",
      "52/52 [==============================] - 6s 118ms/step - loss: 2.3116 - accuracy: 0.1031 - val_loss: 2.2990 - val_accuracy: 0.1356\n",
      "Epoch 4/50\n",
      "52/52 [==============================] - 6s 119ms/step - loss: 2.3058 - accuracy: 0.1164 - val_loss: 2.2979 - val_accuracy: 0.0920\n",
      "Epoch 5/50\n",
      "52/52 [==============================] - 6s 121ms/step - loss: 2.2945 - accuracy: 0.1164 - val_loss: 2.3042 - val_accuracy: 0.0775\n",
      "Epoch 6/50\n",
      "52/52 [==============================] - 6s 122ms/step - loss: 2.2873 - accuracy: 0.1128 - val_loss: 2.2932 - val_accuracy: 0.1525\n",
      "Epoch 7/50\n",
      "52/52 [==============================] - 6s 121ms/step - loss: 2.2633 - accuracy: 0.1407 - val_loss: 2.2473 - val_accuracy: 0.1550\n",
      "Epoch 8/50\n",
      "52/52 [==============================] - 6s 119ms/step - loss: 2.1726 - accuracy: 0.1686 - val_loss: 1.9856 - val_accuracy: 0.2373\n",
      "Epoch 9/50\n",
      "52/52 [==============================] - 6s 119ms/step - loss: 1.9864 - accuracy: 0.2608 - val_loss: 1.8227 - val_accuracy: 0.2421\n",
      "Epoch 10/50\n",
      "52/52 [==============================] - 6s 118ms/step - loss: 1.4740 - accuracy: 0.4463 - val_loss: 0.9207 - val_accuracy: 0.6998\n",
      "Epoch 11/50\n",
      "52/52 [==============================] - 6s 118ms/step - loss: 1.1139 - accuracy: 0.5919 - val_loss: 0.8084 - val_accuracy: 0.7191\n",
      "Epoch 12/50\n",
      "52/52 [==============================] - 6s 118ms/step - loss: 0.8675 - accuracy: 0.6871 - val_loss: 0.6650 - val_accuracy: 0.7554\n",
      "Epoch 13/50\n",
      "52/52 [==============================] - 6s 118ms/step - loss: 0.7169 - accuracy: 0.7374 - val_loss: 0.5854 - val_accuracy: 0.8160\n",
      "Epoch 14/50\n",
      "52/52 [==============================] - 6s 118ms/step - loss: 0.6123 - accuracy: 0.7829 - val_loss: 0.3710 - val_accuracy: 0.8765\n",
      "Epoch 15/50\n",
      "52/52 [==============================] - 6s 119ms/step - loss: 0.4866 - accuracy: 0.8369 - val_loss: 0.4846 - val_accuracy: 0.8450\n",
      "Epoch 16/50\n",
      "52/52 [==============================] - 6s 121ms/step - loss: 0.5350 - accuracy: 0.8114 - val_loss: 0.5098 - val_accuracy: 0.8232\n",
      "Epoch 17/50\n",
      "52/52 [==============================] - 6s 120ms/step - loss: 0.4257 - accuracy: 0.8466 - val_loss: 0.4723 - val_accuracy: 0.8499\n",
      "Epoch 18/50\n",
      "52/52 [==============================] - 6s 120ms/step - loss: 0.3911 - accuracy: 0.8629 - val_loss: 0.3960 - val_accuracy: 0.8741\n",
      "Epoch 19/50\n",
      "52/52 [==============================] - 6s 121ms/step - loss: 0.3198 - accuracy: 0.8896 - val_loss: 0.2608 - val_accuracy: 0.9249\n",
      "Epoch 20/50\n",
      "52/52 [==============================] - 6s 121ms/step - loss: 0.3174 - accuracy: 0.8896 - val_loss: 0.3662 - val_accuracy: 0.8789\n",
      "Epoch 21/50\n",
      "52/52 [==============================] - 6s 121ms/step - loss: 0.3209 - accuracy: 0.8890 - val_loss: 0.2470 - val_accuracy: 0.9322\n",
      "Epoch 22/50\n",
      "52/52 [==============================] - 6s 120ms/step - loss: 0.2785 - accuracy: 0.9078 - val_loss: 0.2448 - val_accuracy: 0.9298\n",
      "Epoch 23/50\n",
      "52/52 [==============================] - 6s 120ms/step - loss: 0.1746 - accuracy: 0.9351 - val_loss: 0.2101 - val_accuracy: 0.9443\n",
      "Epoch 24/50\n",
      "52/52 [==============================] - 6s 120ms/step - loss: 0.2193 - accuracy: 0.9200 - val_loss: 0.2816 - val_accuracy: 0.9153\n",
      "Epoch 25/50\n",
      "52/52 [==============================] - 6s 120ms/step - loss: 0.2029 - accuracy: 0.9303 - val_loss: 0.1815 - val_accuracy: 0.9540\n",
      "Epoch 26/50\n",
      "52/52 [==============================] - 6s 120ms/step - loss: 0.1532 - accuracy: 0.9472 - val_loss: 0.2500 - val_accuracy: 0.9274\n",
      "Epoch 27/50\n",
      "52/52 [==============================] - 6s 119ms/step - loss: 0.1755 - accuracy: 0.9466 - val_loss: 0.2564 - val_accuracy: 0.9346\n",
      "Epoch 28/50\n",
      "52/52 [==============================] - 6s 119ms/step - loss: 0.1698 - accuracy: 0.9388 - val_loss: 0.1778 - val_accuracy: 0.9467\n",
      "Epoch 29/50\n",
      "52/52 [==============================] - 6s 119ms/step - loss: 0.1109 - accuracy: 0.9636 - val_loss: 0.2167 - val_accuracy: 0.9492\n",
      "Epoch 30/50\n",
      "52/52 [==============================] - 6s 120ms/step - loss: 0.1336 - accuracy: 0.9521 - val_loss: 0.2513 - val_accuracy: 0.9225\n",
      "Epoch 31/50\n",
      "52/52 [==============================] - 6s 119ms/step - loss: 0.1439 - accuracy: 0.9515 - val_loss: 0.1878 - val_accuracy: 0.9564\n",
      "Epoch 32/50\n",
      "52/52 [==============================] - 6s 120ms/step - loss: 0.1092 - accuracy: 0.9630 - val_loss: 0.2315 - val_accuracy: 0.9370\n",
      "Epoch 33/50\n",
      "52/52 [==============================] - 6s 120ms/step - loss: 0.0907 - accuracy: 0.9685 - val_loss: 0.2425 - val_accuracy: 0.9370\n",
      "Epoch 34/50\n",
      "52/52 [==============================] - 6s 122ms/step - loss: 0.1213 - accuracy: 0.9576 - val_loss: 0.2830 - val_accuracy: 0.9201\n",
      "Epoch 35/50\n",
      "52/52 [==============================] - 6s 121ms/step - loss: 0.1059 - accuracy: 0.9630 - val_loss: 0.2733 - val_accuracy: 0.9298\n",
      "Epoch 36/50\n",
      "52/52 [==============================] - 6s 120ms/step - loss: 0.1107 - accuracy: 0.9594 - val_loss: 0.1939 - val_accuracy: 0.9492\n",
      "Epoch 37/50\n",
      "52/52 [==============================] - 6s 120ms/step - loss: 0.0740 - accuracy: 0.9697 - val_loss: 0.1391 - val_accuracy: 0.9661\n",
      "Epoch 38/50\n",
      "52/52 [==============================] - 6s 119ms/step - loss: 0.0795 - accuracy: 0.9721 - val_loss: 0.1908 - val_accuracy: 0.9467\n",
      "Epoch 39/50\n",
      "52/52 [==============================] - 6s 120ms/step - loss: 0.0686 - accuracy: 0.9745 - val_loss: 0.2074 - val_accuracy: 0.9492\n",
      "Epoch 40/50\n",
      "52/52 [==============================] - 6s 120ms/step - loss: 0.0757 - accuracy: 0.9715 - val_loss: 0.2020 - val_accuracy: 0.9467\n",
      "Epoch 41/50\n",
      "52/52 [==============================] - 6s 123ms/step - loss: 0.0877 - accuracy: 0.9691 - val_loss: 0.1446 - val_accuracy: 0.9516\n",
      "Epoch 42/50\n",
      "52/52 [==============================] - 6s 120ms/step - loss: 0.0482 - accuracy: 0.9830 - val_loss: 0.1810 - val_accuracy: 0.9564\n",
      "Epoch 43/50\n",
      "52/52 [==============================] - 6s 120ms/step - loss: 0.0632 - accuracy: 0.9770 - val_loss: 0.1555 - val_accuracy: 0.9564\n",
      "Epoch 44/50\n",
      "52/52 [==============================] - 6s 120ms/step - loss: 0.0484 - accuracy: 0.9848 - val_loss: 0.1387 - val_accuracy: 0.9661\n",
      "Epoch 45/50\n",
      "52/52 [==============================] - 6s 120ms/step - loss: 0.0437 - accuracy: 0.9854 - val_loss: 0.3471 - val_accuracy: 0.8959\n",
      "Epoch 46/50\n",
      "52/52 [==============================] - 6s 122ms/step - loss: 0.0600 - accuracy: 0.9794 - val_loss: 0.1436 - val_accuracy: 0.9661\n",
      "Epoch 47/50\n",
      "52/52 [==============================] - 6s 120ms/step - loss: 0.0369 - accuracy: 0.9861 - val_loss: 0.2532 - val_accuracy: 0.9298\n",
      "Epoch 48/50\n",
      "52/52 [==============================] - 6s 119ms/step - loss: 0.0545 - accuracy: 0.9806 - val_loss: 0.1625 - val_accuracy: 0.9637\n",
      "Epoch 49/50\n",
      "52/52 [==============================] - 6s 120ms/step - loss: 0.0461 - accuracy: 0.9861 - val_loss: 0.1833 - val_accuracy: 0.9613\n",
      "Epoch 50/50\n",
      "52/52 [==============================] - 6s 120ms/step - loss: 0.0377 - accuracy: 0.9873 - val_loss: 0.1540 - val_accuracy: 0.9564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbe075a49d0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tuning\n",
    "base_model.trainable = True\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-5),  # Low learning rate\n",
    "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "epochs = 50\n",
    "model.fit(X, Y, epochs=epochs, validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9_1Qr5KL2UM"
   },
   "source": [
    "Accuracy: 98.73%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzhAlsRhcGc1"
   },
   "source": [
    "By comparing model of transfered learning model with \n",
    "Based on the results from model we built from scratch, the accuracy of fully connected model is 71%, accuracy of CNN model is 80.34%. All the five models of transfer learning have a better performance than those two since transfer learning will include the saving of resources and improve efficiety when training new models with complex layers. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
