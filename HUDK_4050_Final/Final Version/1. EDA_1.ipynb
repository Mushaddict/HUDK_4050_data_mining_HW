{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 4050 Final Project--—— Image Recognition of American Sign Language\n",
        "\n",
        "Group 2: Shijie An, Xiaoying Lin, Xinchang Liu, Zhen Xu, Yaxuan Yang\n"
      ],
      "metadata": {
        "id": "98987it_DX1Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Introduction\n",
        "\n",
        "**Sign languages**\n",
        "\n",
        "Sign languages (also known as signed languages) are languages that use manual communication to convey meaning. This can include simultaneously employing hand gestures, movement, orientation of the fingers, arms or body, and facial expressions to convey a speaker's ideas.    \n",
        "    \n",
        "Linguists consider both spoken and signed communication to be types of natural language, meaning that both emerged through an abstract, protracted aging process and evolved over time without meticulous planning. Sign language should not be confused with body language, a type of nonverbal communication. \n",
        "\n",
        "**How do We Apply the Dataset in Education?**\n",
        "\n",
        "Online quiz section in sign language online learning platform,   to improve the interaction of self-learning process \n",
        "Students make the sign language in front of the the computer, camera capture the image\n",
        "Image uploaded to the models\n",
        "Models identify whether the student has made the correct gesture\n",
        "\n"
      ],
      "metadata": {
        "id": "fw8tYe_PEKnF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Dataset Description\n",
        "   \n",
        "    \n",
        "In this dataset, there are 10 classes, which each of them represents the gesture from 1 to 10. Each picture is 100x100 pixels, and there are 218 students participated to give number gestures. There are totally 2062 pictures."
      ],
      "metadata": {
        "id": "E6TCJQxlD4ja"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. EDA"
      ],
      "metadata": {
        "id": "fsJWGy6gDOdh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tm1rk53Gpl4p"
      },
      "outputs": [],
      "source": [
        "## import all the required packages. \n",
        "import os\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "from imageio import imread\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.image_utils import img_to_array\n",
        "\n",
        "import PIL\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LBFxjyCugpk"
      },
      "outputs": [],
      "source": [
        "# Settings \n",
        "num_classes = 10\n",
        "test_size = 0.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aei3nIsElvKZ"
      },
      "source": [
        "\n",
        "This function is used to read the picture from the `data_path` and convert the picture to black and white"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0DSTAtTuoZs"
      },
      "outputs": [],
      "source": [
        "def get_img(data_path): \n",
        "  ## Getting image array from path: \n",
        "  img = PIL.Image.open(data_path)\n",
        "  img = img.convert(\"L\")\n",
        "  img = img_to_array(img)\n",
        "  img = np.resize(img, (100, 100, 1))\n",
        "  return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1eDElM6i80O"
      },
      "source": [
        "Get dataset from picture and then split to train and test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51GeBQZ28elF",
        "outputId": "dd3aa98a-148b-4e90-dbb7-2a8dbb3b1890"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1649, 100, 100, 1)\n",
            "(413, 100, 100, 1)\n",
            "(1649, 10)\n",
            "(413, 10)\n"
          ]
        }
      ],
      "source": [
        "dataset_path = \"/content/drive/MyDrive/HUDK_4050_Final/Dataset\"\n",
        "\n",
        "## Getting all data from data path\n",
        "labels = sorted(listdir(dataset_path)) ## in order to read the files from the sorted list. \n",
        "X = []\n",
        "Y = []\n",
        "for i, label in enumerate(labels): \n",
        "  data_path = dataset_path + \"/\" + label\n",
        "  \n",
        "  for data in listdir(data_path): \n",
        "    ## create dataset \n",
        "    img = get_img(data_path + \"/\" + data)\n",
        "    X.append(img) ## X is the source file for all pictures. \n",
        "    Y.append(i)   ## Y is the number represented for all the picutres. \n",
        "## transfer X, and Y\n",
        "X = 1 - np.array(X).astype(\"float32\") /255\n",
        "Y = np.array(Y).astype(\"float32\")\n",
        "Y = to_categorical(Y, num_classes)\n",
        "## split out the dataset \n",
        "X, X_test, Y, Y_test = train_test_split(X, Y, test_size=test_size, random_state = 42)\n",
        "print(X.shape)\n",
        "print(X_test.shape)\n",
        "print(Y.shape)\n",
        "print(Y_test.shape)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}